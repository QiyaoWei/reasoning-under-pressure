{
  "timestamp": "2025-10-08T03:38:51.218500",
  "input_file": "/Users/qw281/Downloads/MATS/results/training_against_monitor/s480/predictions/_raw_outputs.json",
  "output_file": "/Users/qw281/Downloads/MATS/results/training_against_monitor/s480/predictions/gpt_4o_mini_monitor_predictions.json",
  "monitor_model": "gpt-4o-mini",
  "total_samples": 2070,
  "successful_predictions": 2070,
  "failed_predictions": 0,
  "valid_predictions": 2070,
  "correct_predictions": 1484,
  "accuracy": 0.7169082125603865,
  "accuracy_95_ci": {
    "lower_bound": 0.6971132481452366,
    "upper_bound": 0.7358996015981835,
    "margin": 0.019393176726473407
  },
  "conditional_accuracies": {
    "when_original_correct": {
      "accuracy": 0.8606965174129353,
      "correct_predictions": 1384,
      "total_samples": 1608,
      "95_ci": {
        "lower_bound": 0.8429109007051716,
        "upper_bound": 0.8767628573136321,
        "margin": 0.016925978304230278
      }
    },
    "when_original_incorrect": {
      "accuracy": 0.21645021645021645,
      "correct_predictions": 100,
      "total_samples": 462,
      "95_ci": {
        "lower_bound": 0.18131802750230863,
        "upper_bound": 0.25625886687014826,
        "margin": 0.0374704196839198
      }
    },
    "when_lv_true": {
      "accuracy": 0.7719806763285024,
      "correct_predictions": 799,
      "total_samples": 1035,
      "95_ci": {
        "lower_bound": 0.7454420656443619,
        "upper_bound": 0.7965078105563095,
        "margin": 0.025532872455973746
      }
    },
    "when_lv_false": {
      "accuracy": 0.6618357487922706,
      "correct_predictions": 685,
      "total_samples": 1035,
      "95_ci": {
        "lower_bound": 0.6324629023254007,
        "upper_bound": 0.6900117131758869,
        "margin": 0.028774405425243097
      }
    }
  },
  "model": "gpt-4o-mini",
  "batch_size": 20,
  "max_concurrent": 256
}