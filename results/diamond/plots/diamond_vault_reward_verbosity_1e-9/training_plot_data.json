[
  {
    "step": 460,
    "setting": "Reward verbosity 1e-9 training progress",
    "reasoner_accuracy": 0.8352000000000016,
    "reasoner_accuracy_ci": {
      "lower": 0.8201448600399541,
      "upper": 0.84922659480823,
      "margin": 0.014540867384137996
    },
    "monitors": {
      "gpt-4o-mini": {
        "accuracy": 0.7714975845410628,
        "ci_lower": 0.752917064519092,
        "ci_upper": 0.789072293066213,
        "ci_margin": 0.01807761427356045
      },
      "gpt-4o": {
        "accuracy": 0.6797101449275362,
        "ci_lower": 0.6592931112760047,
        "ci_upper": 0.6994614101149802,
        "ci_margin": 0.020084149419487773
      }
    },
    "incentive_value": null,
    "incentive_se": null
  },
  {
    "step": 465,
    "setting": "Reward verbosity 1e-9 training progress",
    "reasoner_accuracy": 0.8149333333333342,
    "reasoner_accuracy_ci": {
      "lower": 0.799231060246717,
      "upper": 0.8296692485645034,
      "margin": 0.01521909415889325
    },
    "monitors": {
      "gpt-4o-mini": {
        "accuracy": 0.7623188405797101,
        "ci_lower": 0.7435064710458485,
        "ci_upper": 0.7801594029200245,
        "ci_margin": 0.018326465937087956
      },
      "gpt-4o": {
        "accuracy": 0.6768115942028986,
        "ci_lower": 0.6563524195966146,
        "ci_upper": 0.6966157385461287,
        "ci_margin": 0.020131659474757046
      }
    },
    "incentive_value": 360.4084,
    "incentive_se": 0.9103075236924479
  },
  {
    "step": 475,
    "setting": "Reward verbosity 1e-9 training progress",
    "reasoner_accuracy": 0.8001333333333343,
    "reasoner_accuracy_ci": {
      "lower": 0.7840023332212284,
      "upper": 0.8153433886814209,
      "margin": 0.0156705277300962
    },
    "monitors": {
      "gpt-4o-mini": {
        "accuracy": 0.7294685990338164,
        "ci_lower": 0.7099195003677521,
        "ci_upper": 0.7481675901180487,
        "ci_margin": 0.019124044875148245
      },
      "gpt-4o": {
        "accuracy": 0.6347826086956522,
        "ci_lower": 0.6138086361872619,
        "ci_upper": 0.6552572548559767,
        "ci_margin": 0.02072430933435742
      }
    },
    "incentive_value": 379.8184,
    "incentive_se": 1.0865520543088072
  },
  {
    "step": 485,
    "setting": "Reward verbosity 1e-9 training progress",
    "reasoner_accuracy": 0.8126666666666675,
    "reasoner_accuracy_ci": {
      "lower": 0.796896445145328,
      "upper": 0.8274774854907059,
      "margin": 0.015290520172688978
    },
    "monitors": {
      "gpt-4o-mini": {
        "accuracy": 0.7381642512077294,
        "ci_lower": 0.7187966339906404,
        "ci_upper": 0.7566495462398852,
        "ci_margin": 0.01892645612462235
      },
      "gpt-4o": {
        "accuracy": 0.6492753623188405,
        "ci_lower": 0.6284590035030676,
        "ci_upper": 0.6695387037813795,
        "ci_margin": 0.020539850139155953
      }
    },
    "incentive_value": 716.8556,
    "incentive_se": 0.9559402011230876
  },
  {
    "step": 495,
    "setting": "Reward verbosity 1e-9 training progress",
    "reasoner_accuracy": 0.8238666666666677,
    "reasoner_accuracy_ci": {
      "lower": 0.8084406485676608,
      "upper": 0.8382989154045893,
      "margin": 0.014929133418464196
    },
    "monitors": {
      "gpt-4o-mini": {
        "accuracy": 0.7545893719806763,
        "ci_lower": 0.7355908723047591,
        "ci_upper": 0.772644699665803,
        "ci_margin": 0.018526913680521975
      },
      "gpt-4o": {
        "accuracy": 0.6681159420289855,
        "ci_lower": 0.6475356103567839,
        "ci_upper": 0.6880734580412343,
        "ci_margin": 0.02026892384222524
      }
    },
    "incentive_value": 696.4012,
    "incentive_se": 1.4131307054835063
  },
  {
    "step": 505,
    "setting": "Reward verbosity 1e-9 training progress",
    "reasoner_accuracy": 0.8138666666666676,
    "reasoner_accuracy_ci": {
      "lower": 0.7981323119045087,
      "upper": 0.8286379365889769,
      "margin": 0.015252812342234063
    },
    "monitors": {
      "gpt-4o-mini": {
        "accuracy": 0.748792270531401,
        "ci_lower": 0.7296594669975356,
        "ci_upper": 0.7670033784765429,
        "ci_margin": 0.0186719557395036
      },
      "gpt-4o": {
        "accuracy": 0.6458937198067632,
        "ci_lower": 0.6250387491060699,
        "ci_upper": 0.6662082010554286,
        "ci_margin": 0.020584725974679353
      }
    },
    "incentive_value": 706.7232,
    "incentive_se": 1.088983905796056
  },
  {
    "step": 515,
    "setting": "Reward verbosity 1e-9 training progress",
    "reasoner_accuracy": 0.8249333333333336,
    "reasoner_accuracy_ci": {
      "lower": 0.8095412267017337,
      "upper": 0.83932839758825,
      "margin": 0.014893585443258103
    },
    "monitors": {
      "gpt-4o-mini": {
        "accuracy": 0.7541062801932367,
        "ci_lower": 0.7350964171765386,
        "ci_upper": 0.7721747609193164,
        "ci_margin": 0.018539171871388923
      },
      "gpt-4o": {
        "accuracy": 0.6647342995169082,
        "ci_lower": 0.6441089595473464,
        "ci_upper": 0.6847493517277232,
        "ci_margin": 0.02032019609018837
      }
    },
    "incentive_value": 729.2224,
    "incentive_se": 0.3453231450769125
  },
  {
    "step": 525,
    "setting": "Reward verbosity 1e-9 training progress",
    "reasoner_accuracy": 0.833733333333334,
    "reasoner_accuracy_ci": {
      "lower": 0.818628855798458,
      "upper": 0.8478137661128389,
      "margin": 0.014592455157190421
    },
    "monitors": {
      "gpt-4o-mini": {
        "accuracy": 0.7632850241545893,
        "ci_lower": 0.744496499650769,
        "ci_upper": 0.7810981620645179,
        "ci_margin": 0.01830083120687441
      },
      "gpt-4o": {
        "accuracy": 0.6700483091787439,
        "ci_lower": 0.6494942238804918,
        "ci_upper": 0.6899724200163541,
        "ci_margin": 0.02023909806793108
      }
    },
    "incentive_value": 730.0456,
    "incentive_se": 0.3440350451638908
  },
  {
    "step": 535,
    "setting": "Reward verbosity 1e-9 training progress",
    "reasoner_accuracy": 0.8350666666666677,
    "reasoner_accuracy_ci": {
      "lower": 0.8200070245507263,
      "upper": 0.84909817275774,
      "margin": 0.014545574103506896
    },
    "monitors": {
      "gpt-4o-mini": {
        "accuracy": 0.7632850241545893,
        "ci_lower": 0.744496499650769,
        "ci_upper": 0.7810981620645179,
        "ci_margin": 0.01830083120687441
      },
      "gpt-4o": {
        "accuracy": 0.6594202898550725,
        "ci_lower": 0.6387265769829586,
        "ci_upper": 0.6795234016703344,
        "ci_margin": 0.02039841234368787
      }
    },
    "incentive_value": 811.7992,
    "incentive_se": 0.998928052787516
  },
  {
    "step": 545,
    "setting": "Reward verbosity 1e-9 training progress",
    "reasoner_accuracy": 0.8290666666666677,
    "reasoner_accuracy_ci": {
      "lower": 0.8138078916348412,
      "upper": 0.8433157163863665,
      "margin": 0.014753912375762594
    },
    "monitors": {
      "gpt-4o-mini": {
        "accuracy": 0.7521739130434782,
        "ci_lower": 0.7331189096374612,
        "ci_upper": 0.7702946929595661,
        "ci_margin": 0.01858789166105246
      },
      "gpt-4o": {
        "accuracy": 0.6521739130434783,
        "ci_lower": 0.631391549166941,
        "ci_upper": 0.6723925213657479,
        "ci_margin": 0.020500486099403466
      }
    },
    "incentive_value": 850.61,
    "incentive_se": 0.6864812179404721
  },
  {
    "step": 555,
    "setting": "Reward verbosity 1e-9 training progress",
    "reasoner_accuracy": 0.8316000000000012,
    "reasoner_accuracy_ci": {
      "lower": 0.8164244836836406,
      "upper": 0.8457580175921876,
      "margin": 0.014666766954273444
    },
    "monitors": {
      "gpt-4o-mini": {
        "accuracy": 0.7676328502415459,
        "ci_lower": 0.7489532501269057,
        "ci_upper": 0.7853209564607438,
        "ci_margin": 0.018183853166919024
      },
      "gpt-4o": {
        "accuracy": 0.6611889801836636,
        "ci_lower": 0.6405126476462389,
        "ci_upper": 0.6812678711491916,
        "ci_margin": 0.0203776117514763
      }
    },
    "incentive_value": 858.32,
    "incentive_se": 0.5537150893375257
  }
]