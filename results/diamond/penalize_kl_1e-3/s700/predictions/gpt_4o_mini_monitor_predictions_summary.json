{
  "timestamp": "2025-10-09T02:52:40.635639",
  "input_file": "/Users/qw281/Downloads/MATS/results/penalize_kl_1e-3/s700/predictions/_raw_outputs.json",
  "output_file": "/Users/qw281/Downloads/MATS/results/penalize_kl_1e-3/s700/predictions/gpt_4o_mini_monitor_predictions.json",
  "monitor_model": "gpt-4o-mini",
  "total_samples": 2070,
  "successful_predictions": 2070,
  "failed_predictions": 0,
  "valid_predictions": 2070,
  "correct_predictions": 1617,
  "accuracy": 0.7811594202898551,
  "accuracy_95_ci": {
    "lower_bound": 0.7628361582779001,
    "upper_bound": 0.7984410768015441,
    "margin": 0.017802459261821963
  },
  "conditional_accuracies": {
    "when_original_correct": {
      "accuracy": 0.8846376811594203,
      "correct_predictions": 1526,
      "total_samples": 1725,
      "95_ci": {
        "lower_bound": 0.8687001671140421,
        "upper_bound": 0.898865877319665,
        "margin": 0.015082855102811505
      }
    },
    "when_original_incorrect": {
      "accuracy": 0.263768115942029,
      "correct_predictions": 91,
      "total_samples": 345,
      "95_ci": {
        "lower_bound": 0.2200527085656645,
        "upper_bound": 0.3126863169187385,
        "margin": 0.04631680417653701
      }
    },
    "when_lv_true": {
      "accuracy": 0.8531400966183574,
      "correct_predictions": 883,
      "total_samples": 1035,
      "95_ci": {
        "lower_bound": 0.8302700614663548,
        "upper_bound": 0.8733984278812307,
        "margin": 0.02156418320743788
      }
    },
    "when_lv_false": {
      "accuracy": 0.7091787439613526,
      "correct_predictions": 734,
      "total_samples": 1035,
      "95_ci": {
        "lower_bound": 0.6807781766214229,
        "upper_bound": 0.7360322965488979,
        "margin": 0.02762705996373752
      }
    }
  },
  "model": "gpt-4o-mini",
  "batch_size": 20,
  "max_concurrent": 256
}