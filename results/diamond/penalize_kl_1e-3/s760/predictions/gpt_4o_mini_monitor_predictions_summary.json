{
  "timestamp": "2025-10-09T02:53:01.457241",
  "input_file": "/Users/qw281/Downloads/MATS/results/penalize_kl_1e-3/s760/predictions/_raw_outputs.json",
  "output_file": "/Users/qw281/Downloads/MATS/results/penalize_kl_1e-3/s760/predictions/gpt_4o_mini_monitor_predictions.json",
  "monitor_model": "gpt-4o-mini",
  "total_samples": 2070,
  "successful_predictions": 2070,
  "failed_predictions": 0,
  "valid_predictions": 2070,
  "correct_predictions": 1678,
  "accuracy": 0.8106280193236715,
  "accuracy_95_ci": {
    "lower_bound": 0.7931800444081972,
    "upper_bound": 0.8269252170283706,
    "margin": 0.01687258631008665
  },
  "conditional_accuracies": {
    "when_original_correct": {
      "accuracy": 0.9049826187717266,
      "correct_predictions": 1562,
      "total_samples": 1726,
      "95_ci": {
        "lower_bound": 0.8902353584383499,
        "upper_bound": 0.9179311893521486,
        "margin": 0.01384791545689933
      }
    },
    "when_original_incorrect": {
      "accuracy": 0.3372093023255814,
      "correct_predictions": 116,
      "total_samples": 344,
      "95_ci": {
        "lower_bound": 0.2892930176252596,
        "upper_bound": 0.38872121224912126,
        "margin": 0.04971409731193085
      }
    },
    "when_lv_true": {
      "accuracy": 0.8492753623188406,
      "correct_predictions": 879,
      "total_samples": 1035,
      "95_ci": {
        "lower_bound": 0.8261889583606981,
        "upper_bound": 0.8697786446465583,
        "margin": 0.021794843142930103
      }
    },
    "when_lv_false": {
      "accuracy": 0.7719806763285024,
      "correct_predictions": 799,
      "total_samples": 1035,
      "95_ci": {
        "lower_bound": 0.7454420656443619,
        "upper_bound": 0.7965078105563095,
        "margin": 0.025532872455973746
      }
    }
  },
  "model": "gpt-4o-mini",
  "batch_size": 20,
  "max_concurrent": 256
}