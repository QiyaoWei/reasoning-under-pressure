{
  "timestamp": "2025-09-25T14:37:18.039251",
  "input_file": "results/reward_monitorability/k=2/step_260/predictions/reward_monitorability_k3_step_260_raw_outputs.json",
  "output_file": "results/reward_monitorability/k=2/step_260/predictions/gpt_4o_monitor_predictions.json",
  "total_samples": 1518,
  "successful_predictions": 1518,
  "failed_predictions": 0,
  "valid_predictions": 1518,
  "correct_predictions": 1161,
  "accuracy": 0.7648221343873518,
  "accuracy_95_ci": {
    "lower_bound": 0.7428352247910165,
    "upper_bound": 0.7854721066592886,
    "margin": 0.021318440934136013
  },
  "conditional_accuracies": {
    "when_original_correct": {
      "accuracy": 0.9510050251256281,
      "correct_predictions": 757,
      "total_samples": 796,
      "95_ci": {
        "lower_bound": 0.9337235716479041,
        "upper_bound": 0.963954326992955,
        "margin": 0.015115377672525429
      }
    },
    "when_original_incorrect": {
      "accuracy": 0.5595567867036011,
      "correct_predictions": 404,
      "total_samples": 722,
      "95_ci": {
        "lower_bound": 0.5231246602038027,
        "upper_bound": 0.5953585139865059,
        "margin": 0.03611692689135156
      }
    },
    "when_lv_true": {
      "accuracy": 0.7022397891963109,
      "correct_predictions": 533,
      "total_samples": 759,
      "95_ci": {
        "lower_bound": 0.6687559636108164,
        "upper_bound": 0.733686767378927,
        "margin": 0.03246540188405534
      }
    },
    "when_lv_false": {
      "accuracy": 0.8274044795783926,
      "correct_predictions": 628,
      "total_samples": 759,
      "95_ci": {
        "lower_bound": 0.7988884691144432,
        "upper_bound": 0.8526230530415907,
        "margin": 0.02686729196357372
      }
    }
  },
  "model": "gpt-4o",
  "batch_size": 20,
  "max_concurrent": 256
}