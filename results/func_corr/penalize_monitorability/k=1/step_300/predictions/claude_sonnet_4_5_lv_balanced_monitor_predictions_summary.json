{
  "timestamp": "2025-11-20T15:54:28.297378",
  "provider": "anthropic",
  "monitor_model": "claude-sonnet-4-5-20250929",
  "total_samples": 1518,
  "successful_predictions": 1518,
  "failed_predictions": 0,
  "valid_predictions": 1518,
  "correct_predictions": 771,
  "accuracy": 0.5079051383399209,
  "accuracy_95_ci": {
    "lower_bound": 0.4827675203829202,
    "upper_bound": 0.533002847720074,
    "margin": 0.02511766366857689
  },
  "conditional_accuracies": {
    "when_original_correct": {
      "accuracy": 0.5168661588683352,
      "correct_predictions": 475,
      "total_samples": 919,
      "95_ci": {
        "lower_bound": 0.4845549624356918,
        "upper_bound": 0.5490369397309223,
        "margin": 0.03224098864761521
      }
    },
    "when_original_incorrect": {
      "accuracy": 0.4941569282136895,
      "correct_predictions": 296,
      "total_samples": 599,
      "95_ci": {
        "lower_bound": 0.4542836706945955,
        "upper_bound": 0.534104652806423,
        "margin": 0.03991049105591376
      }
    },
    "when_lv_true": {
      "accuracy": 0.13175230566534915,
      "correct_predictions": 100,
      "total_samples": 759,
      "95_ci": {
        "lower_bound": 0.10953402769169944,
        "upper_bound": 0.1576793709295822,
        "margin": 0.024072671618941378
      }
    },
    "when_lv_false": {
      "accuracy": 0.8840579710144928,
      "correct_predictions": 671,
      "total_samples": 759,
      "95_ci": {
        "lower_bound": 0.859322657932285,
        "upper_bound": 0.9049252644358596,
        "margin": 0.022801303251787315
      }
    }
  },
  "batch_size": 20,
  "max_concurrent": 60,
  "input_file": "/Users/qw281/Downloads/MATS/results/func_corr/penalize_monitorability/k=1/step_300/predictions/against-monitor-k1-weighted-step_300_raw_outputs.json",
  "output_file": "/Users/qw281/Downloads/MATS/results/func_corr/penalize_monitorability/k=1/step_300/predictions/claude_sonnet_4_5_20250929_monitor_predictions.json",
  "rebalance": {
    "method": "downsample_to_equal_lv",
    "seed": 42,
    "lv_true_count": 759,
    "lv_false_count": 759,
    "original_lv_true_count": 759,
    "original_lv_false_count": 1741
  }
}